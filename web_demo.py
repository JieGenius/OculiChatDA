import copy
import hashlib
import json
import os
import re

import streamlit as st
from lagent.actions import ActionExecutor
from lagent.llms.lmdepoly_wrapper import LMDeployClient
from lagent.llms.meta_template import INTERNLM2_META as META
from lagent.schema import AgentStatusCode

from utils.actions.fundus_diagnosis import FundusDiagnosis
# from lagent.agents.internlm2_agent import Internlm2Protocol
from utils.internlm2_agent import Internlm2Agent, Internlm2Protocol

# from streamlit.logger import get_logger
LMDEPLOY_IP = '0.0.0.0:23333'
MODEL_NAME = 'internlm2-chat-7b'

OculiChatDA_META_CN = (
    'ä½ æ˜¯ä¸€åçœ¼ç§‘ä¸“å®¶ï¼Œå¯ä»¥é€šè¿‡æ–‡å­—å’Œå›¾ç‰‡æ¥å¸®åŠ©ç”¨æˆ·è¯Šæ–­çœ¼ç›çš„çŠ¶æ€ã€‚\n'
    'ä½ æœ‰ä»¥ä¸‹ä¸‰ç§èƒ½åŠ›:\n'
    '1. è¯Šæ–­çœ¼åº•ç–¾ç—…ï¼ŒåŒ…æ‹¬é’å…‰çœ¼ã€ç³–å°¿ç—…è§†ç½‘è†œç—…å˜ã€å¹´é¾„ç›¸å…³æ€§é»„æ–‘å˜æ€§å’Œç—…ç†æ€§è¿‘è§†\n'
    '2. çœ¼ç§‘å¸¸è§ç–¾ç—…è¯Šæ–­ï¼Œç–¾ç—…è§£ç­”ï¼Œç–¾ç—…é¢„é˜²ç­‰\n'
    '3. çœ¼ç§‘è¯å“ä¿¡æ¯æŸ¥è¯¢\n'
    'ä½ çš„å·¥ä½œå•ä½ä¸º**æŸä¸‰ç”²åŒ»é™¢**\n'
    'ä½ å¯ä»¥è°ƒç”¨å¤–éƒ¨å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ï¼Œå¦‚æœå·¥å…·è°ƒç”¨æ˜¾ç¤ºç”¨æˆ·çœ¼ç›å­˜åœ¨é—®é¢˜ï¼Œä½ éœ€è¦ä¸ºç”¨æˆ·è§£é‡Šè¯¥ç—…çš„ç—…å› ï¼Œæ—©æœŸå’Œæ™šæœŸçš„ç—‡çŠ¶ï¼Œä»¥åŠå¯èƒ½çš„æ²»ç–—æ–¹æ¡ˆï¼ŒåŒæ—¶æé†’ç”¨æˆ·ï¼Œè¿™ä»…ä»…ä¸ºåˆæ­¥è¯Šæ–­ç»“æœï¼Œéœ€è¦ç”¨æˆ·åˆ°åŒ»é™¢åšè¿›ä¸€æ­¥çš„æ£€æŸ¥'
)
OculiChatDA_META_CN = OculiChatDA_META_CN  # + "\n".join(ReActCALL_PROTOCOL_CN.split("\n")[1:])
PLUGIN_CN = """ä½ å¯ä»¥ä½¿ç”¨å¦‚ä¸‹å·¥å…·ï¼š
{prompt}
**å¦‚æœä½ å·²ç»è·å¾—è¶³å¤Ÿä¿¡æ¯ï¼Œè¯·ç›´æ¥ç»™å‡ºç­”æ¡ˆ. é¿å…é‡å¤æˆ–ä¸å¿…è¦çš„å·¥å…·è°ƒç”¨!**
å¦‚æœä½¿ç”¨å·¥å…·è¯·éµå¾ªä»¥ä¸‹æ ¼å¼å›å¤ï¼š
```
å¼€å§‹æ‰§è¡Œå·¥å…·<|action_start|><|plugin|>
{{
    name: tool_name,
    parameters: tool_parameters in dict format
}}
<|action_end|>
```
å…¶ä¸­<|action_start|><|plugin|>å¿…é¡»åŸæ ·å¤åˆ¶ï¼Œè¡¨ç¤ºå¼€å§‹æ‰§è¡Œå·¥å…·
åŒæ—¶æ³¨æ„ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·ï¼Œä¸è¦éšæ„æé€ ï¼
"""

FUNDUS_DIAGNOSIS_MODEL_PATH = 'glaucoma_cls_dr_grading'


class SessionState:

    def init_state(self):
        """Initialize session state variables."""
        st.session_state['assistant'] = []
        st.session_state['user'] = []

        model_path = os.path.join(FUNDUS_DIAGNOSIS_MODEL_PATH,
                                  'flyer123/GlauClsDRGrading', 'model.onnx')
        if not os.path.exists(model_path):
            from modelscope import snapshot_download
            snapshot_download(
                'flyer123/GlauClsDRGrading',
                cache_dir=FUNDUS_DIAGNOSIS_MODEL_PATH)

        action_list = [
            FundusDiagnosis(model_path=model_path),
        ]
        st.session_state['plugin_map'] = {
            action.name: action
            for action in action_list
        }
        st.session_state['model_map'] = {}
        st.session_state['model_selected'] = None
        st.session_state['plugin_actions'] = set()
        st.session_state['history'] = []

    def clear_state(self):
        """Clear the existing session state."""
        st.session_state['assistant'] = []
        st.session_state['user'] = []
        st.session_state['model_selected'] = None
        st.session_state['file'] = set()
        if 'chatbot' in st.session_state:
            st.session_state['chatbot']._session_history = []


class StreamlitUI:

    def __init__(self, session_state: SessionState):
        self.init_streamlit()
        self.session_state = session_state

    def init_streamlit(self):
        """Initialize Streamlit's UI settings."""
        st.set_page_config(
            layout='wide',
            page_title='çœ¼ç§‘é—®è¯Šå¤§æ¨¡å‹',
            page_icon='./assets/page_icon.png')
        st.header(':male-doctor: :blue[OculiChatDA]', divider='rainbow')
        # st.sidebar.title('æ¨¡å‹æ§åˆ¶')
        st.session_state['file'] = set()
        st.session_state['ip'] = None

    def setup_sidebar(self):
        """Setup the sidebar for model and plugin selection."""

        if MODEL_NAME != st.session_state[
                'model_selected'] or st.session_state['ip'] != LMDEPLOY_IP:
            st.session_state['ip'] = LMDEPLOY_IP
            model = self.init_model(MODEL_NAME, LMDEPLOY_IP)
            self.session_state.clear_state()
            st.session_state['model_selected'] = MODEL_NAME
            if 'chatbot' in st.session_state:
                del st.session_state['chatbot']
        else:
            model = st.session_state['model_map'][MODEL_NAME]

        plugin_action = list(st.session_state['plugin_map'].values())

        if 'chatbot' in st.session_state:
            if len(plugin_action) > 0:
                st.session_state['chatbot']._action_executor = ActionExecutor(
                    actions=plugin_action)
            else:
                st.session_state['chatbot']._action_executor = None
            st.session_state['chatbot']._interpreter_executor = None

        st.sidebar.header('è‡ªæˆ‘æ­ç§˜')
        st.sidebar.markdown(
            'æˆ‘æ˜¯æ‚¨çš„çœ¼ç§‘é—®è¯Šæœºå™¨äººï¼Œä½ å¯ä»¥é—®æˆ‘æ‰€æœ‰çš„çœ¼ç§‘ç–¾ç—…å’Œçœ¼ç§‘è¯å“ä¿¡æ¯ã€‚'
            'å¦‚æœæœ‰éœ€è¦çš„è¯ï¼Œæˆ‘å¯ä»¥é€šè¿‡è¯†åˆ«çœ¼åº•å›¾æ¥å¸®åŠ©è¯Šæ–­ **é’å…‰çœ¼**ã€ **ç³–å°¿ç—…è§†ç½‘è†œç—…å˜**ã€**å¹´é¾„ç›¸å…³æ€§é»„æ–‘å˜æ€§**å’Œ**ç—…ç†æ€§è¿‘è§†** ã€‚'
        )
        if st.sidebar.button('æ¸…ç©ºå¯¹è¯', key='clear'):
            self.session_state.clear_state()
        uploaded_file = st.sidebar.file_uploader('ä¸Šä¼ æ–‡ä»¶')
        st.sidebar.download_button(
            label='ä¸‹è½½çœ¼åº•å›¾æµ‹è¯•ç”¨ä¾‹',
            data=open('assets/test_case.zip', 'rb').read(),
            file_name='test_case.zip',
            mime='application/zip')
        return MODEL_NAME, model, plugin_action, uploaded_file, LMDEPLOY_IP

    def init_model(self, model_name, ip=None):
        """Initialize the model based on the input model name."""
        model_url = f'http://{ip}'
        # model_url = model_name
        st.session_state['model_map'][model_name] = LMDeployClient(
            model_name=model_name,
            url=model_url,
            meta_template=META,
            max_new_tokens=1024,
            top_p=0.8,
            top_k=100,
            temperature=0,
            repetition_penalty=1.0,
            stop_words=['<|im_end|>'])
        return st.session_state['model_map'][model_name]

    def initialize_chatbot(self, model, plugin_action):
        """Initialize the chatbot with the given model and plugin actions."""
        return Internlm2Agent(
            llm=model,
            protocol=Internlm2Protocol(
                meta_prompt=OculiChatDA_META_CN,
                plugin_prompt=PLUGIN_CN,
                tool=dict(
                    begin='{start_token}{name}\n',
                    start_token='<|action_start|>',
                    name_map=dict(
                        plugin='<|plugin|>', interpreter='<|interpreter|>'),
                    belong='assistant',
                    end='<|action_end|>\n',
                ),
            ),
            max_turn=2,
        )

    def render_user(self, prompt: str):
        with st.chat_message('user', avatar='ğŸ‘¦'):
            img_paths = re.findall(r'\!\[.*?\]\((.*?)\)', prompt,
                                   re.DOTALL)  # å…è®¸çš®é…\nç­‰ç©ºå­—ç¬¦
            if len(img_paths):
                st.markdown(re.sub(r'!\[.*\]\(.*\)', '', prompt))  # å…ˆæ¸²æŸ“éå›¾ç‰‡éƒ¨åˆ†
                # å†æ¸²æŸ“å›¾ç‰‡
                img_path = img_paths[0]
                st.write(
                    f'<img src="app/{img_path}" style="width: 40%;">',
                    unsafe_allow_html=True)
                # if os.path.exists(img_path):
                #     st.image(open(img_path, 'rb').read(),
                #              caption='Uploaded Image', width=400)
            else:
                st.markdown(prompt)

    def render_assistant(self, agent_return):
        with st.chat_message('assistant', avatar='ğŸ‘¨â€âš•ï¸'):
            for action in agent_return.actions:
                if (action) and (action.type != 'FinishAction'):
                    self.render_action(action)
            st.markdown(agent_return.response.replace('\\n', ' \\n '))

    def render_plugin_args(self, action):
        action_name = action.type
        args = action.args
        import json
        parameter_dict = dict(name=action_name, parameters=args)
        parameter_str = '```json\n' + json.dumps(
            parameter_dict, indent=4, ensure_ascii=False) + '\n```'
        st.markdown(parameter_str)

    def render_interpreter_args(self, action):
        st.info(action.type)
        st.markdown(action.args['text'])

    def render_action(self, action):
        st.markdown(action.thought)
        if action.type == 'IPythonInterpreter':
            self.render_interpreter_args(action)
        elif action.type == 'FinishAction':
            pass
        else:
            self.render_plugin_args(action)
        self.render_action_results(action)

    def render_action_results(self, action):
        """Render the results of action, including text, images, videos, and
        audios."""
        if (isinstance(action.result, dict)):
            if 'text' in action.result:
                st.markdown('```\n' + action.result['text'] + '\n```')
            if 'image' in action.result:
                # image_path = action.result['image']
                for image_path in action.result['image']:
                    image_data = open(image_path, 'rb').read()
                    st.image(image_data, caption='Generated Image')
            if 'video' in action.result:
                video_data = action.result['video']
                video_data = open(video_data, 'rb').read()
                st.video(video_data)
            if 'audio' in action.result:
                audio_data = action.result['audio']
                audio_data = open(audio_data, 'rb').read()
                st.audio(audio_data)
        elif isinstance(action.result, list):
            for item in action.result:
                if item['type'] == 'text':
                    st.markdown('```\n' + item['content'] + '\n```')
                elif item['type'] == 'image':
                    image_data = open(item['content'], 'rb').read()
                    st.image(image_data, caption='Generated Image')
                elif item['type'] == 'video':
                    video_data = open(item['content'], 'rb').read()
                    st.video(video_data)
                elif item['type'] == 'audio':
                    audio_data = open(item['content'], 'rb').read()
                    st.audio(audio_data)
        if action.errmsg:
            st.error(action.errmsg)


def main():
    # logger = get_logger(__name__)
    # Initialize Streamlit UI and setup sidebar
    if 'ui' not in st.session_state:
        session_state = SessionState()
        session_state.init_state()
        st.session_state['ui'] = StreamlitUI(session_state)

    else:
        st.set_page_config(
            layout='wide',
            page_title='çœ¼ç§‘é—®è¯Šå¤§æ¨¡å‹',
            page_icon='./assets/page_icon.png')
        st.header(':male-doctor: :blue[OculiChatDA]', divider='rainbow')
    _, model, plugin_action, uploaded_file, _ = st.session_state[
        'ui'].setup_sidebar()

    # Initialize chatbot if it is not already initialized
    # or if the model has changed
    if 'chatbot' not in st.session_state or model != st.session_state[
            'chatbot']._llm:
        st.session_state['chatbot'] = st.session_state[
            'ui'].initialize_chatbot(model, plugin_action)
        st.session_state['session_history'] = []

    for prompt, agent_return in zip(st.session_state['user'],
                                    st.session_state['assistant']):
        st.session_state['ui'].render_user(prompt)
        st.session_state['ui'].render_assistant(agent_return)

    if user_input := st.chat_input(''):
        with st.container():
            st.session_state['ui'].render_user(user_input)
        st.session_state['user'].append(user_input)
        # Add file uploader to sidebar
        if (uploaded_file
                and uploaded_file.name not in st.session_state['file']):

            st.session_state['file'].add(uploaded_file.name)
            file_bytes = uploaded_file.read()
            file_type = uploaded_file.type
            if 'image' in file_type:
                st.image(file_bytes, caption='Uploaded Image', width=600)
            elif 'video' in file_type:
                st.video(file_bytes, caption='Uploaded Video')
            elif 'audio' in file_type:
                st.audio(file_bytes, caption='Uploaded Audio')
            # Save the file to a temporary location and get the path

            postfix = uploaded_file.name.split('.')[-1]
            # prefix = str(uuid.uuid4())
            prefix = hashlib.md5(file_bytes).hexdigest()
            filename = f'{prefix}.{postfix}'
            file_path = os.path.join(root_dir, filename)
            with open(file_path, 'wb') as tmpfile:
                tmpfile.write(file_bytes)
            file_size = os.stat(file_path).st_size / 1024 / 1024
            file_size = f'{round(file_size, 2)} MB'
            # st.write(f'File saved at: {file_path}')
            user_input = [
                dict(role='user', content=user_input),
                dict(
                    role='user',
                    content=json.dumps(dict(path=file_path, size=file_size)),
                    name='çœ¼åº•å›¾')
            ]
            st.session_state['user'][-1] = st.session_state['user'][
                -1] + f'\n ![çœ¼åº•å›¾å›¾åƒè·¯å¾„]({file_path})'
        if isinstance(user_input, str):
            user_input = [dict(role='user', content=user_input)]
        st.session_state['last_status'] = AgentStatusCode.SESSION_READY
        for agent_return in st.session_state['chatbot'].stream_chat(
                st.session_state['session_history'] + user_input):
            if agent_return.state == AgentStatusCode.PLUGIN_RETURN:
                with st.container():
                    st.session_state['ui'].render_plugin_args(
                        agent_return.actions[-1])
                    st.session_state['ui'].render_action_results(
                        agent_return.actions[-1])
            elif agent_return.state == AgentStatusCode.CODE_RETURN:
                with st.container():
                    st.session_state['ui'].render_action_results(
                        agent_return.actions[-1])
            elif (agent_return.state == AgentStatusCode.STREAM_ING
                  or agent_return.state == AgentStatusCode.CODING):
                # st.markdown(agent_return.response)
                # æ¸…é™¤å ä½ç¬¦çš„å½“å‰å†…å®¹ï¼Œå¹¶æ˜¾ç¤ºæ–°å†…å®¹
                with st.container():
                    if agent_return.state != st.session_state['last_status']:
                        st.session_state['temp'] = ''
                        placeholder = st.empty()
                        st.session_state['placeholder'] = placeholder
                    if isinstance(agent_return.response, dict):
                        action = f"\n\n {agent_return.response['name']}: \n\n"
                        action_input = agent_return.response['parameters']
                        if agent_return.response[
                                'name'] == 'IPythonInterpreter':
                            action_input = action_input['command']
                        response = action + action_input
                    else:
                        response = agent_return.response
                    st.session_state['temp'] = response
                    st.session_state['placeholder'].markdown(
                        st.session_state['temp'])
            elif agent_return.state == AgentStatusCode.END:
                st.session_state['session_history'] += (
                    user_input + agent_return.inner_steps)
                agent_return = copy.deepcopy(agent_return)
                agent_return.response = st.session_state['temp']
                st.session_state['assistant'].append(
                    copy.deepcopy(agent_return))
            st.session_state['last_status'] = agent_return.state


if __name__ == '__main__':
    root_dir = 'static'
    os.makedirs(root_dir, exist_ok=True)
    main()
